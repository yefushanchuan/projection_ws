import cv2
import numpy as np
from hobot_dnn import pyeasy_dnn as dnn //åº•å±‚

class BPU_Detect:
    def __init__(self, model_path:str,
                labelnames:list,
                num_classes:int = None,
                conf:float = 0.45,
                iou:float = 0.45,
                anchors:np.array = np.array([
                    [10,13, 16,30, 33,23],  # P3/8
                    [30,61, 62,45, 59,119],  # P4/16
                    [116,90, 156,198, 373,326],  # P5/32
                   ]),
                strides = np.array([8, 16, 32]),
                mode:bool = False,
                window_created = False,
                is_save:bool = False
                ):
        self.model_path = model_path
        self.models = dnn.load(self.model_path)
        self.model = self.models[0]  # è·å–ç¬¬ä¸€ä¸ªæ¨¡å‹
        self.labelname = labelnames
        self.conf = conf
        self.iou = iou
        self.anchors = anchors
        self.strides = strides
        self.input_shape = self.model.inputs[0].properties.shape
        self.input_w = self.input_shape[2]  # NCHWæ ¼å¼
        self.input_h = self.input_shape[3]
        self.nc = num_classes if num_classes is not None else len(self.labelname)
        self.window_created = window_created
        self.is_save = is_save
        self._init_grids()

    def _init_grids(self) :
            """åˆå§‹åŒ–ç‰¹å¾å›¾ç½‘æ ¼"""
            def _create_grid(stride: int) :
                """åˆ›å»ºå•ä¸ªstrideçš„ç½‘æ ¼å’Œanchors"""
                grid = np.stack([
                    np.tile(np.linspace(0.5, self.input_w//stride - 0.5, self.input_w//stride), 
                        reps=self.input_h//stride),
                    np.repeat(np.arange(0.5, self.input_h//stride + 0.5, 1), 
                            self.input_w//stride)
                ], axis=0).transpose(1,0)
                grid = np.hstack([grid] * 3).reshape(-1, 2)
                
                anchors = np.tile(
                    self.anchors[int(np.log2(stride/8))], 
                    self.input_w//stride * self.input_h//stride
                ).reshape(-1, 2)
                
                return grid, anchors
                
            # åˆ›å»ºä¸åŒå°ºåº¦çš„ç½‘æ ¼
            self.s_grid, self.s_anchors = _create_grid(self.strides[0])
            self.m_grid, self.m_anchors = _create_grid(self.strides[1]) 
            self.l_grid, self.l_anchors = _create_grid(self.strides[2])
            
            """print(f"ç½‘æ ¼å°ºå¯¸: {self.s_grid.shape = }  {self.m_grid.shape = }  {self.l_grid.shape = }")
            print(f"Anchorså°ºå¯¸: {self.s_anchors.shape = }  {self.m_anchors.shape = }  {self.l_anchors.shape = }")"""


    def bgr2nv12_opencv(self, image):
        height, width = image.shape[0], image.shape[1]
        area = height * width
        yuv420p = cv2.cvtColor(image, cv2.COLOR_BGR2YUV_I420).reshape((area * 3 // 2,))
        y = yuv420p[:area]
        uv_planar = yuv420p[area:].reshape((2, area // 4))
        uv_packed = uv_planar.transpose((1, 0)).reshape((area // 2,))

        nv12 = np.zeros_like(yuv420p)
        nv12[:height * width] = y
        nv12[height * width:] = uv_packed
        return  nv12
    
    def PreProcess(self, img):#é¢„å¤„ç†å‡½æ•°
        if isinstance(img, str):
            # å¦‚æœè¾“å…¥æ˜¯å­—ç¬¦ä¸² (æ—§é€»è¾‘)ï¼Œåˆ™ä»æ–‡ä»¶è¯»å–
            orig_img = cv2.imread(img)
            if orig_img is None:
                raise ValueError(f"æ— æ³•è¯»å–å›¾ç‰‡: {img}")
        elif isinstance(img, np.ndarray):
            # å¦‚æœè¾“å…¥æ˜¯NumPyæ•°ç»„ (æ–°é€»è¾‘)ï¼Œç›´æ¥ä½¿ç”¨å®ƒ
            orig_img = img
        else:
            raise TypeError(f"ä¸æ”¯æŒçš„è¾“å…¥ç±»å‹: {type(img)}ã€‚è¯·è¾“å…¥ str æˆ– numpy.ndarrayã€‚")

        # ä¿æŒæ¯”ä¾‹ç¼©æ”¾ + å¡«å……ï¼Œå¹¶è¿”å›æ¯”ä¾‹å’Œpadding
        def letterbox(image, new_shape=(640, 640), color=(114, 114, 114)):
            shape = image.shape[:2]  # (h, w)
            r = min(new_shape[0] / shape[0], new_shape[1] / shape[1])  # ç¼©æ”¾æ¯”ä¾‹
            new_unpad = (int(round(shape[1] * r)), int(round(shape[0] * r)))  # ç¼©æ”¾åå°ºå¯¸ (w, h)

            # ç¼©æ”¾
            resized = cv2.resize(image, new_unpad, interpolation=cv2.INTER_LINEAR)

            # è®¡ç®—å¡«å……
            dw = new_shape[1] - new_unpad[0]  # width padding
            dh = new_shape[0] - new_unpad[1]  # height padding
            top, bottom = dh // 2, dh - dh // 2
            left, right = dw // 2, dw - dw // 2

            # å¡«å……
            padded = cv2.copyMakeBorder(resized, top, bottom, left, right,
                                        cv2.BORDER_CONSTANT, value=color)

            return padded, r, (left, top)

        # è°ƒç”¨ letterbox
        input_tensor, ratio, (pad_w, pad_h) = letterbox(orig_img, (self.input_h, self.input_w))
        self.ratio = ratio
        self.pad_w = pad_w
        self.pad_h = pad_h  
        # è½¬æ¢é¢œè‰²æ ¼å¼
        input_tensor = self.bgr2nv12_opencv(input_tensor)

        # é€å…¥æ¨ç†
        return input_tensor

    def PostProcess(self):
        outputs = self.model_outputs
            
        # å¤„ç†ä¸‰ä¸ªè¾“å‡ºå±‚
        s_pred = outputs[0].buffer.reshape([-1, (5 + self.nc)])
        m_pred = outputs[1].buffer.reshape([-1, (5 + self.nc)])
        l_pred = outputs[2].buffer.reshape([-1, (5 + self.nc)])

        # classify: åˆ©ç”¨numpyå‘é‡åŒ–æ“ä½œå®Œæˆé˜ˆå€¼ç­›é€‰
        s_raw_max_scores = np.max(s_pred[:, 5:], axis=1)
        s_max_scores = 1 / ((1 + np.exp(-s_pred[:, 4]))*(1 + np.exp(-s_raw_max_scores)))
        s_valid_indices = np.flatnonzero(s_max_scores >= self.conf)
        s_ids = np.argmax(s_pred[s_valid_indices, 5:], axis=1)
        s_scores = s_max_scores[s_valid_indices]

        m_raw_max_scores = np.max(m_pred[:, 5:], axis=1)
        m_max_scores = 1 / ((1 + np.exp(-m_pred[:, 4]))*(1 + np.exp(-m_raw_max_scores)))
        m_valid_indices = np.flatnonzero(m_max_scores >= self.conf)
        m_ids = np.argmax(m_pred[m_valid_indices, 5:], axis=1)
        m_scores = m_max_scores[m_valid_indices]

        l_raw_max_scores = np.max(l_pred[:, 5:], axis=1)
        l_max_scores = 1 / ((1 + np.exp(-l_pred[:, 4]))*(1 + np.exp(-l_raw_max_scores)))
        l_valid_indices = np.flatnonzero(l_max_scores >= self.conf)
        l_ids = np.argmax(l_pred[l_valid_indices, 5:], axis=1)
        l_scores = l_max_scores[l_valid_indices]

        # ç‰¹å¾è§£ç 
        s_dxyhw = 1 / (1 + np.exp(-s_pred[s_valid_indices, :4]))
        s_xy = (s_dxyhw[:, 0:2] * 2.0 + self.s_grid[s_valid_indices,:] - 1.0) * self.strides[0]
        s_wh = (s_dxyhw[:, 2:4] * 2.0) ** 2 * self.s_anchors[s_valid_indices, :]
        s_xyxy = np.concatenate([s_xy - s_wh * 0.5, s_xy + s_wh * 0.5], axis=-1)

        m_dxyhw = 1 / (1 + np.exp(-m_pred[m_valid_indices, :4]))
        m_xy = (m_dxyhw[:, 0:2] * 2.0 + self.m_grid[m_valid_indices,:] - 1.0) * self.strides[1]
        m_wh = (m_dxyhw[:, 2:4] * 2.0) ** 2 * self.m_anchors[m_valid_indices, :]
        m_xyxy = np.concatenate([m_xy - m_wh * 0.5, m_xy + m_wh * 0.5], axis=-1)

        l_dxyhw = 1 / (1 + np.exp(-l_pred[l_valid_indices, :4]))
        l_xy = (l_dxyhw[:, 0:2] * 2.0 + self.l_grid[l_valid_indices,:] - 1.0) * self.strides[2]
        l_wh = (l_dxyhw[:, 2:4] * 2.0) ** 2 * self.l_anchors[l_valid_indices, :]
        l_xyxy = np.concatenate([l_xy - l_wh * 0.5, l_xy + l_wh * 0.5], axis=-1)

        # å¤§ä¸­å°ç‰¹å¾å±‚é˜ˆå€¼ç­›é€‰ç»“æœæ‹¼æ¥
        xyxy = np.concatenate((s_xyxy, m_xyxy, l_xyxy), axis=0)
        scores = np.concatenate((s_scores, m_scores, l_scores), axis=0)
        ids = np.concatenate((s_ids, m_ids, l_ids), axis=0)

        xyxy[:, [0, 2]] -= self.pad_w  # xæ–¹å‘å»é™¤padå®½åº¦
        xyxy[:, [1, 3]] -= self.pad_h  # yæ–¹å‘å»é™¤padé«˜åº¦
        xyxy /= self.ratio            # é™¤ä»¥ç¼©æ”¾æ¯”ä¾‹è¿˜åŸåŸå›¾å°ºå¯¸

        # NMSå¤„ç†
        indices = cv2.dnn.NMSBoxes(xyxy.tolist(), scores.tolist(), self.conf, self.iou)

        if len(indices) > 0:
            indices = np.array(indices).flatten()
            self.bboxes = xyxy[indices].astype(np.int32)
            self.scores = scores[indices]
            self.ids = ids[indices]

            # # ğŸš€ åªä¿ç•™ "person" ç±»åˆ« (COCO çš„ id = 0)
            # mask = (ids == 0)
            # self.bboxes = bboxes[mask]
            # self.scores = scores[mask]
            # self.ids = ids[mask]

            self.centers = []
            for (x1, y1, x2, y2) in self.bboxes:
                cx = (x1 + x2) // 2
                cy = (y1 + y2) // 2
                self.centers.append((cx, cy))

#            for i, (cx, cy) in enumerate(self.centers):
#                print(f"ç¬¬{i}ä¸ªæ¡†çš„ä¸­å¿ƒç‚¹åæ ‡ï¼š({cx}, {cy})")
                
        else:
#            print("No detections after NMS")
            self.bboxes = np.array([], dtype=np.int32).reshape(0, 4)
            self.scores = np.array([], dtype=np.float32)
            self.ids = np.array([], dtype=np.int32)
            self.centers = []

    def draw_detection(self,img: np.array, 
                        box,
                        score: float, 
                        class_id: int,
                        labelname: list):
        x1, y1, x2, y2 = box
        rdk_colors = [
            (255, 0, 0),    # çº¢è‰²
            (0, 255, 0),    # ç»¿è‰²
            (0, 0, 255),    # è“è‰²
            (255, 255, 0),  # é»„è‰²
            (255, 0, 255),  # ç´«è‰²
            (0, 255, 255),  # é’è‰²
        ]
        color = rdk_colors[class_id % len(rdk_colors)]
        cv2.rectangle(img, (x1, y1), (x2, y2), color, 2)
        label = f"{labelname[class_id]}: {score:.2f}"
        (label_width, label_height), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)
        label_x = x1
        label_y = y1 - 10 if y1 - 10 > label_height else y1 + 10
        cv2.rectangle(
            img, 
            (label_x, label_y - label_height), 
            (label_x + label_width, label_y + label_height), 
            color, 
            cv2.FILLED
        )
        cv2.putText(img, label, (label_x, label_y), 
                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)

    def detect_result(self, img, show_img):
        # 1. é€»è¾‘ï¼šå¦‚æœä¸ä¿å­˜ä¹Ÿä¸æ˜¾ç¤ºï¼Œåˆ™å°è¯•å…³é—­çª—å£
        if not self.is_save and not show_img:
            # åªæœ‰å½“çª—å£ç¡®å®å­˜åœ¨æ—¶æ‰å»é”€æ¯
            if self.window_created:
                try:
                    cv2.destroyWindow("Detection Result")
                except cv2.error:
                    pass # é˜²æ­¢çª—å£å·²ç»è¢«ç”¨æˆ·æ‰‹åŠ¨å…³é—­äº†æŠ¥é”™
                self.window_created = False
                cv2.waitKey(1) # åˆ·æ–°äº‹ä»¶å¾ªç¯
            return

        # 2. å‡†å¤‡å›¾ç‰‡æ•°æ®
        if isinstance(img, str):
            draw_img = cv2.imread(img)
        elif isinstance(img, np.ndarray):
            draw_img = img.copy()
        else:
            return
        
        # 3. ç»˜åˆ¶æ£€æµ‹æ¡†
        for class_id, score, bbox in zip(self.ids, self.scores, self.bboxes):
            x1, y1, x2, y2 = bbox
            self.draw_detection(draw_img, (x1, y1, x2, y2), score, class_id, self.labelname)

        # 4. ä¿å­˜å›¾ç‰‡
        if self.is_save:
            cv2.imwrite("result.jpg", draw_img)
        
        # 5. æ˜¾ç¤ºé€»è¾‘ (å¢å¼ºé²æ£’æ€§ç‰ˆ)
        if show_img:
            # æ£€æŸ¥çª—å£æ˜¯å¦çœŸçš„å­˜åœ¨ (é˜²æ­¢ self.window_created çŠ¶æ€ä¸åŒæ­¥)
            # WND_PROP_VISIBLE åœ¨æŸäº› backend ä¸Šå¯èƒ½ä¸å¯ç”¨ï¼Œä½†é€šå¸¸ç”¨æ¥æ£€æµ‹çª—å£æ˜¯å¦å­˜åœ¨
            try:
                is_win_visible = cv2.getWindowProperty("Detection Result", cv2.WND_PROP_VISIBLE)
            except:
                is_win_visible = -1

            # å¦‚æœæ ‡è®°ä¸ºæœªåˆ›å»ºï¼Œæˆ–è€…æ£€æµ‹åˆ°çª—å£å®é™…ä¸Šå·²ç»ä¸åœ¨äº†ï¼ˆè¢«ç”¨æˆ·ç‚¹Xå…³é—­ï¼‰
            if not self.window_created or is_win_visible < 1.0:
                cv2.namedWindow("Detection Result", cv2.WINDOW_NORMAL)
                cv2.setWindowProperty("Detection Result", cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_FULLSCREEN)
                self.window_created = True
                print("Window Re-created!") # ç»ˆç«¯æ‰“å°ä¸€ä¸‹ï¼Œæ–¹ä¾¿è°ƒè¯•

            cv2.imshow("Detection Result", draw_img)
            
            # ã€å…³é”®ä¿®æ”¹ã€‘ç¨å¾®å¢åŠ ç­‰å¾…æ—¶é—´ï¼Œä» 1ms æ”¹ä¸º 10ms
            # è¿™æœ‰åŠ©äºåœ¨çª—å£åˆšåˆ›å»ºæ—¶å¤„ç†ç§¯å‹çš„ GUI äº‹ä»¶
            cv2.waitKey(10)
  
    def detect(self, img, show_img=True):
        """
        æ£€æµ‹å‡½æ•°
        Args:
            img: å›¾ç‰‡
            show_img: æ˜¯å¦æ˜¾ç¤ºå›¾ç‰‡çª—å£ (bool)
        """
        # é¢„å¤„ç†
        input_tensor = self.PreProcess(img)
        
        # æ¨ç†å’Œåå¤„ç†
        self.model_outputs = self.model.forward(input_tensor)
        self.PostProcess()
        
        # å°†å¼€å…³ä¼ é€’ç»™å¯è§†åŒ–å‡½æ•°
        self.detect_result(img, show_img)

if __name__ == "__main__":
    labelname = [
    "person", "bicycle", "car", "motorcycle", "airplane", "bus", "train", "truck", "boat", "traffic light", 
    "fire hydrant", "stop sign", "parking meter", "bench", "bird", "cat", "dog", "horse", "sheep", "cow", 
    "elephant", "bear", "zebra", "giraffe", "backpack", "umbrella", "handbag", "tie", "suitcase", "frisbee", 
    "skis", "snowboard", "sports ball", "kite", "baseball bat", "baseball glove", "skateboard", "surfboard", "tennis racket", "bottle", 
    "wine glass", "cup", "fork", "knife", "spoon", "bowl", "banana", "apple", "sandwich", "orange", 
    "broccoli", "carrot", "hot dog", "pizza", "donut", "cake", "chair", "couch", "potted plant", "bed", 
    "dining table", "toilet", "tv", "laptop", "mouse", "remote", "keyboard", "cell phone", "microwave", "oven", 
    "toaster", "sink", "refrigerator", "book", "clock", "vase", "scissors", "teddy bear", "hair drier", "toothbrush"
    ]
    test_img = "../dog.jpeg"
    model_path = "../models/yolov5s_tag_v7.0_detect_640x640_bayese_nv12.bin"
    infer = BPU_Detect(model_path, labelname, conf = 0.1, mode = False, is_save = True)
    infer.detect(test_img, method_post = 1)